{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb440f5-176e-4774-a5d0-f2e22761cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extract_grain_sizes(file_path):\n",
    "    \"\"\"Extracts grain sizes from a given text file.\"\"\"\n",
    "    grain_sizes = []\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            match = re.search(r'Group \\d+: (\\d+) elements, ([\\d.]+) total area', line)\n",
    "            if match:\n",
    "                total_area = float(match.group(2))\n",
    "                grain_sizes.append(total_area)\n",
    "    return grain_sizes\n",
    "\n",
    "def compute_average_grain_size(sample_folder):\n",
    "    \"\"\"Computes the average grain size for a given sample, excluding the file with the largest grain size,\n",
    "       and removing values that are more than 50% smaller than the average in a second pass.\"\"\"\n",
    "    grain_sizes = []\n",
    "    # outlier_file = find_outlier_file(sample_folder)\n",
    "    \n",
    "    for file_name in os.listdir(sample_folder):\n",
    "        # if file_name == outlier_file:\n",
    "            # continue  # Skip the file with the largest grain size\n",
    "        file_path = os.path.join(sample_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            grain_sizes.extend(extract_grain_sizes(file_path))\n",
    "    \n",
    "    if not grain_sizes:\n",
    "        return None\n",
    "    \n",
    "    # Initial average calculation\n",
    "    avg_grain_size = sum(grain_sizes) / len(grain_sizes)\n",
    "    \n",
    "    # Remove values that are more than 50% smaller than the average\n",
    "    # filtered_grain_sizes = [size for size in grain_sizes if size >= 0.5 * avg_grain_size]\n",
    "    \n",
    "    # if filtered_grain_sizes:\n",
    "    #     avg_grain_size = sum(filtered_grain_sizes) / len(filtered_grain_sizes)\n",
    "    \n",
    "    return avg_grain_size\n",
    "\n",
    "def main(root_folder, output_file):\n",
    "    \"\"\"Processes all samples and writes the average grain size to an output file in alphabetical order.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for sample_name in os.listdir(root_folder):\n",
    "        sample_folder = os.path.join(root_folder, sample_name)\n",
    "        if os.path.isdir(sample_folder):\n",
    "            avg_grain_size = compute_average_grain_size(sample_folder)\n",
    "            if avg_grain_size is not None:\n",
    "                results[sample_name] = avg_grain_size\n",
    "    \n",
    "    with open(output_file, 'w') as out_file:\n",
    "        for sample_name in sorted(results.keys()):\n",
    "            out_file.write(f\"{sample_name}: {results[sample_name]:.2f} pixels\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_folder = \"voronoi_outputs/mixed_dots/\"  # Replace with actual folder path\n",
    "    output_file = \"grain_size_summary_mixed.txt\"\n",
    "    main(root_folder, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
